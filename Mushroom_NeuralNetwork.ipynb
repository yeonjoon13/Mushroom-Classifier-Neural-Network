{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation and exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from typing import List, Dict, Tuple, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features=22, h1=8, h2=9, out_features=2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features, h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.out = nn.Linear(h2, out_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.out(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model2(nn.Module):\n",
    "    def __init__(self, in_features=22, h1=3, h2=4, out_features=2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features, h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.out = nn.Linear(h2, out_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.out(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model3(nn.Module):\n",
    "    def __init__(self, in_features=22, h1=2, h2=3, h3=2, out_features=2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features, h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.fc3 = nn.Linear(h2,h3)\n",
    "        self.out = nn.Linear(h3, out_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = torch.sigmoid(self.out(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model4(nn.Module):\n",
    "    def __init__(self, in_features=22, h1=7, h2=8, h3=7, out_features=2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features, h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.fc3 = nn.Linear(h2,h3)\n",
    "        self.out = nn.Linear(h3, out_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = torch.sigmoid(self.out(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model5(nn.Module):\n",
    "    def __init__(self, in_features=22, h1=2, h2=2, h3=2, h4=2, out_features=2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features, h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.fc3 = nn.Linear(h2,h3)\n",
    "        self.fc4 = nn.Linear(h3,h4)\n",
    "        self.out = nn.Linear(h4, out_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = torch.sigmoid(self.out(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model6(nn.Module):\n",
    "    def __init__(self, in_features=22, h1=7, h2=8, h3=8, h4=7, out_features=2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features, h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.fc3 = nn.Linear(h2,h3)\n",
    "        self.fc4 = nn.Linear(h3,h4)\n",
    "        self.out = nn.Linear(h4, out_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = torch.sigmoid(self.out(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(41)\n",
    "model = Model()\n",
    "model2 = Model2()\n",
    "model3 = Model3()\n",
    "model4 = Model4()\n",
    "model5 = Model5()\n",
    "model6 = Model6()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(file_name):\n",
    "    data = []\n",
    "    file = open(file_name, \"r\")\n",
    "    for line in file:\n",
    "        datum = [value for value in line.rstrip().split(\",\")]\n",
    "        data.append(datum)\n",
    "    random.shuffle(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_names_mushroom = [\"edible\",'cap-shape',\n",
    "                   'cap-surface',\n",
    "                   'cap-color',\n",
    "                   'bruises?',\n",
    "                   'odor',\n",
    "                   'gill-attachment',\n",
    "                   'gill-spacing',\n",
    "                   'gill-size',\n",
    "                   'gill-color',\n",
    "                   'stalk-shape',\n",
    "                   'stalk-root',\n",
    "                   'stalk-surface-above-ring',\n",
    "                   'stalk-surface-below-ring',\n",
    "                   'stalk-color-above-ring',\n",
    "                   'stalk-color-below-ring',\n",
    "                   'veil-type',\n",
    "                   'veil-color',\n",
    "                   'ring-number',\n",
    "                   'ring-type',\n",
    "                   'spore-print-color',\n",
    "                   'population',\n",
    "                   'habitat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.read_csv(\"agaricus-lepiota.data\", names=attribute_names_mushroom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "for column in my_df.columns:\n",
    "    my_df[column] = label_encoder.fit_transform(my_df[column])\n",
    "    \n",
    "X = my_df.drop(columns=['edible']) \n",
    "y = my_df['edible']\n",
    "\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(model, X_train, y_train, X_val, y_val, n_splits=10):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "    train_errors = []\n",
    "    val_errors = []\n",
    "    \n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(X_train)):\n",
    "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        epochs = 100\n",
    "        for i in range(epochs):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_train_fold)\n",
    "            loss = criterion(y_pred, y_train_fold)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        train_pred = torch.argmax(model(X_train_fold), dim=1)\n",
    "        val_pred = torch.argmax(model(X_val_fold), dim=1)\n",
    "        \n",
    "        train_error = (train_pred != y_train_fold).float().mean().item()\n",
    "        val_error = (val_pred != y_val_fold).float().mean().item()\n",
    "        \n",
    "        train_errors.append(train_error)\n",
    "        val_errors.append(val_error)\n",
    "        \n",
    "        print(f'Fold: {fold}\\tTrain Error: {train_error*100:.2f}%\\tValidation Error: {val_error*100:.2f}%')\n",
    "    \n",
    "    train_errors = np.array(train_errors)\n",
    "    val_errors = np.array(val_errors)\n",
    "    \n",
    "    print(\"\\nMean(Std. Dev.) over all folds:\")\n",
    "    print(\"-------------------------------\")\n",
    "    print(f\"Train Error: {train_errors.mean()*100:.2f}% ({train_errors.std()*100:.2f}%)\")\n",
    "    print(f\"Validation Error: {val_errors.mean()*100:.2f}% ({val_errors.std()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: \n",
      "Fold: 0\tTrain Error: 5.23%\tValidation Error: 5.54%\n",
      "Fold: 1\tTrain Error: 5.28%\tValidation Error: 4.77%\n",
      "Fold: 2\tTrain Error: 5.23%\tValidation Error: 5.23%\n",
      "Fold: 3\tTrain Error: 5.25%\tValidation Error: 5.08%\n",
      "Fold: 4\tTrain Error: 5.20%\tValidation Error: 5.54%\n",
      "Fold: 5\tTrain Error: 5.16%\tValidation Error: 5.85%\n",
      "Fold: 6\tTrain Error: 5.18%\tValidation Error: 5.69%\n",
      "Fold: 7\tTrain Error: 5.32%\tValidation Error: 4.46%\n",
      "Fold: 8\tTrain Error: 5.23%\tValidation Error: 5.23%\n",
      "Fold: 9\tTrain Error: 5.26%\tValidation Error: 4.93%\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 5.23% (0.04%)\n",
      "Validation Error: 5.23% (0.41%)\n",
      "\n",
      "\n",
      "Model 2: \n",
      "Fold: 0\tTrain Error: 28.36%\tValidation Error: 27.38%\n",
      "Fold: 1\tTrain Error: 27.63%\tValidation Error: 26.92%\n",
      "Fold: 2\tTrain Error: 26.91%\tValidation Error: 29.69%\n",
      "Fold: 3\tTrain Error: 27.24%\tValidation Error: 23.23%\n",
      "Fold: 4\tTrain Error: 26.64%\tValidation Error: 28.15%\n",
      "Fold: 5\tTrain Error: 26.59%\tValidation Error: 25.85%\n",
      "Fold: 6\tTrain Error: 26.47%\tValidation Error: 26.92%\n",
      "Fold: 7\tTrain Error: 26.84%\tValidation Error: 23.54%\n",
      "Fold: 8\tTrain Error: 26.31%\tValidation Error: 28.31%\n",
      "Fold: 9\tTrain Error: 26.15%\tValidation Error: 29.74%\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 26.91% (0.64%)\n",
      "Validation Error: 26.97% (2.13%)\n",
      "\n",
      "\n",
      "Model 3: \n",
      "Fold: 0\tTrain Error: 48.33%\tValidation Error: 47.23%\n",
      "Fold: 1\tTrain Error: 48.25%\tValidation Error: 48.00%\n",
      "Fold: 2\tTrain Error: 48.11%\tValidation Error: 49.23%\n",
      "Fold: 3\tTrain Error: 48.44%\tValidation Error: 46.31%\n",
      "Fold: 4\tTrain Error: 47.87%\tValidation Error: 51.38%\n",
      "Fold: 5\tTrain Error: 47.96%\tValidation Error: 50.62%\n",
      "Fold: 6\tTrain Error: 48.13%\tValidation Error: 49.08%\n",
      "Fold: 7\tTrain Error: 48.18%\tValidation Error: 48.62%\n",
      "Fold: 8\tTrain Error: 48.38%\tValidation Error: 46.77%\n",
      "Fold: 9\tTrain Error: 48.58%\tValidation Error: 44.99%\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 48.22% (0.21%)\n",
      "Validation Error: 48.22% (1.87%)\n",
      "\n",
      "\n",
      "Model 4: \n",
      "Fold: 0\tTrain Error: 5.52%\tValidation Error: 5.85%\n",
      "Fold: 1\tTrain Error: 5.44%\tValidation Error: 6.15%\n",
      "Fold: 2\tTrain Error: 5.54%\tValidation Error: 5.23%\n",
      "Fold: 3\tTrain Error: 5.49%\tValidation Error: 5.69%\n",
      "Fold: 4\tTrain Error: 5.69%\tValidation Error: 3.85%\n",
      "Fold: 5\tTrain Error: 5.56%\tValidation Error: 5.08%\n",
      "Fold: 6\tTrain Error: 5.64%\tValidation Error: 4.31%\n",
      "Fold: 7\tTrain Error: 5.40%\tValidation Error: 6.46%\n",
      "Fold: 8\tTrain Error: 5.39%\tValidation Error: 6.62%\n",
      "Fold: 9\tTrain Error: 5.45%\tValidation Error: 6.01%\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 5.51% (0.10%)\n",
      "Validation Error: 5.52% (0.86%)\n",
      "\n",
      "\n",
      "Model 5: \n",
      "Fold: 0\tTrain Error: 48.40%\tValidation Error: 46.62%\n",
      "Fold: 1\tTrain Error: 48.38%\tValidation Error: 46.77%\n",
      "Fold: 2\tTrain Error: 48.21%\tValidation Error: 48.31%\n",
      "Fold: 3\tTrain Error: 47.99%\tValidation Error: 50.31%\n",
      "Fold: 4\tTrain Error: 48.66%\tValidation Error: 44.31%\n",
      "Fold: 5\tTrain Error: 48.14%\tValidation Error: 48.92%\n",
      "Fold: 6\tTrain Error: 47.89%\tValidation Error: 51.23%\n",
      "Fold: 7\tTrain Error: 48.14%\tValidation Error: 48.92%\n",
      "Fold: 8\tTrain Error: 48.06%\tValidation Error: 49.69%\n",
      "Fold: 9\tTrain Error: 48.34%\tValidation Error: 47.15%\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 48.22% (0.22%)\n",
      "Validation Error: 48.22% (1.94%)\n",
      "\n",
      "\n",
      "Model 6: \n",
      "Fold: 0\tTrain Error: 5.45%\tValidation Error: 6.77%\n",
      "Fold: 1\tTrain Error: 5.47%\tValidation Error: 4.31%\n",
      "Fold: 2\tTrain Error: 5.27%\tValidation Error: 5.08%\n",
      "Fold: 3\tTrain Error: 5.32%\tValidation Error: 4.46%\n",
      "Fold: 4\tTrain Error: 5.16%\tValidation Error: 5.85%\n",
      "Fold: 5\tTrain Error: 5.40%\tValidation Error: 3.69%\n",
      "Fold: 6\tTrain Error: 5.16%\tValidation Error: 5.85%\n",
      "Fold: 7\tTrain Error: 5.04%\tValidation Error: 6.92%\n",
      "Fold: 8\tTrain Error: 5.18%\tValidation Error: 5.69%\n",
      "Fold: 9\tTrain Error: 5.33%\tValidation Error: 4.31%\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 5.28% (0.13%)\n",
      "Validation Error: 5.29% (1.04%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Model 1: \")\n",
    "cross_validate(model, X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor)\n",
    "print('\\n')\n",
    "print(\"Model 2: \")\n",
    "cross_validate(model2, X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor)\n",
    "print('\\n')\n",
    "print(\"Model 3: \")\n",
    "cross_validate(model3, X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor)\n",
    "print('\\n')\n",
    "print(\"Model 4: \")\n",
    "cross_validate(model4, X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor)\n",
    "print('\\n')\n",
    "print(\"Model 5: \")\n",
    "cross_validate(model5, X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor)\n",
    "print('\\n')\n",
    "print(\"Model 6: \")\n",
    "cross_validate(model6, X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\tTrain Error: 5.20%\tValidation Error: 5.54%\n",
      "Fold: 1\tTrain Error: 5.27%\tValidation Error: 4.92%\n",
      "Fold: 2\tTrain Error: 5.25%\tValidation Error: 5.08%\n",
      "Fold: 3\tTrain Error: 5.18%\tValidation Error: 5.69%\n",
      "Fold: 4\tTrain Error: 5.16%\tValidation Error: 5.85%\n",
      "Fold: 5\tTrain Error: 5.21%\tValidation Error: 5.38%\n",
      "Fold: 6\tTrain Error: 5.27%\tValidation Error: 4.92%\n",
      "Fold: 7\tTrain Error: 5.35%\tValidation Error: 4.15%\n",
      "Fold: 8\tTrain Error: 5.09%\tValidation Error: 6.46%\n",
      "Fold: 9\tTrain Error: 5.33%\tValidation Error: 4.31%\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 5.23% (0.07%)\n",
      "Validation Error: 5.23% (0.67%)\n"
     ]
    }
   ],
   "source": [
    "cross_validate(model, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model got 94.08866995073892% correct\n",
      "The model got 5.911330049261082% incorrect\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    for i,data in enumerate(X_test_tensor):\n",
    "        y_val = model.forward(data)\n",
    "\n",
    "        if y_val.argmax().item() == y_test_tensor[i]:\n",
    "            correct += 1\n",
    "            \n",
    "print(f'The model got {(correct / len(X_test_tensor)) * 100}% correct')\n",
    "print(f'The model got {100 - ((correct / len(X_test_tensor)) * 100)}% incorrect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3724)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "with torch.no_grad():\n",
    "    y_eval = model.forward(X_test_tensor)\n",
    "    loss = criterion(y_eval, y_test_tensor)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "I created 6 different models with varying number of layers and units per layer. <br />\n",
    "Model 1: Number of layers: 2, Units per layer: 8,9 <br />\n",
    "Model 2: Number of layers: 2, Units per layer: 3,4 <br />\n",
    "Model 3: Number of layers: 3, Units per layer: 2,3,2 <br />\n",
    "Model 4: Number of layers: 3, Units per layer: 7,8,7 <br />\n",
    "Model 5: Number of layers: 4, Units per layer: 2,2,2,2 <br />\n",
    "Model 6: Number of layers: 4, Units per layer: 7,8,8,7 <br />\n",
    "\n",
    "I trained my models using a lr = 0.01 and epochs = 100. I also set `torch.manual_seed(41)` so that outputs are reproducable. \n",
    "\n",
    "I split my training, testing, and validation sets into a 8:1:1 ratio. \n",
    "\n",
    "I created different folds by using sklearn's library 'Kfold'.\n",
    "\n",
    "### Winning Model / Results\n",
    "My winning model would be Model 1 because I can see that the traing and validation errior were the lowest compared to all the other models. This is important because it determines which model has the optimal bias/variance tradeoff. We put strong attention to the validation error because it is a big indicator on how well the model will do on the test data. \n",
    "\n",
    "Model 1: Train Error: Train Error: 5.23% (0.04%) Validation Error: 5.23% (0.41%) <br />\n",
    "Model 2: Train Error: 26.91% (0.64%) Validation Error: 26.97% (2.13%) <br />\n",
    "Model 3: Train Error: 48.22% (0.15%) Validation Error: 48.22% (1.36%) <br />\n",
    "Model 4: Train Error: 5.51% (0.10%) Validation Error: 5.52% (0.86%) <br />\n",
    "Model 5: Train Error: 48.22% (0.17%) Validation Error: 48.22% (1.54%) <br />\n",
    "Model 6: Train Error: Train Error: 5.28% (0.13%) Validation Error: 5.29% (1.04%) <br />\n",
    "\n",
    "As we can see from the results, the models with greater units per layer do better than the models with less units per layer. We can also see that the number of layers is not as a determining factor compared to the units per layer as Model 1, 4, 6 tend to have similar errors. \n",
    "\n",
    "Final test error: 5.23% <br />\n",
    "Loss: 0.3724\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before You Submit...\n",
    "\n",
    "1. Re-read the general instructions provided above, and\n",
    "2. Hit \"Kernel\"->\"Restart & Run All\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "81px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
